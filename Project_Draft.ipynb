{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Project Description\n",
    "\n",
    "The goal is to create a web application, introducing a trading algorithm which gives a suggestion to buy, not buy, sell, or hold, and then executes that trade through user input.\n",
    "\n",
    "Trading platform will be Alpaca. Server will be on Replit. Web App will be on Anvil. See links below.\n",
    "\n",
    "The algorithm will look at historical stock data 1 year prior to current date. It will use the parameters which can be retrieved from Alpaca to train the model. \n",
    "\n",
    "The model will also include sentiment score as an independent variable, which means historical articles from each day will need to be pulled to give an average sentiment score. \n",
    "\n",
    "The model will be trained on the top 10 stocks in 2024 in the S&P 500 by index weight. \n",
    "\n",
    "The model will output a prediction for the next week. Based on its prediction, the model will suggest to buy, not buy, sell, or hold."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Links\n",
    "\n",
    "https://anvil.works/\n",
    "\n",
    "https://app.alpaca.markets/paper/dashboard/overview\n",
    "\n",
    "https://replit.com/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Login Information\n",
    "\n",
    "Email: nshuckerow@ucsd.edu\n",
    "\n",
    "Password: MGTA415data!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                         time     open     high      low    close  volume\n",
      "0   2023-08-21 00:00:00-04:00  317.855  322.725  317.130  321.940  408350\n",
      "1   2023-08-22 00:00:00-04:00  325.540  325.900  321.520  322.450  326147\n",
      "2   2023-08-23 00:00:00-04:00  323.770  329.190  323.480  326.975  311403\n",
      "3   2023-08-24 00:00:00-04:00  332.870  332.870  319.990  320.040  473996\n",
      "4   2023-08-25 00:00:00-04:00  321.595  325.075  318.900  322.860  303301\n",
      "..                        ...      ...      ...      ...      ...     ...\n",
      "246 2024-08-13 00:00:00-04:00  409.610  414.880  409.610  413.780  247042\n",
      "247 2024-08-14 00:00:00-04:00  415.190  417.690  412.565  416.655  231308\n",
      "248 2024-08-15 00:00:00-04:00  419.610  421.085  417.690  420.870  320490\n",
      "249 2024-08-16 00:00:00-04:00  420.775  420.945  417.330  418.500  192582\n",
      "250 2024-08-19 00:00:00-04:00  419.080  421.560  416.480  421.450  211362\n",
      "\n",
      "[251 rows x 6 columns]\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import alpaca_trade_api as tradeapi\n",
    "from datetime import datetime, timedelta\n",
    "import pandas as pd\n",
    "\n",
    "# Alpaca API credentials\n",
    "ALPACA_API_KEY = \"PKDFQIPQCXE38TAG1WKG\"\n",
    "ALPACA_SECRET_KEY = \"LRaWwamsMm0WDa58x8S0z8wje9gRcYhcgtMf7C55\"\n",
    "ALPACA_URL = 'https://paper-api.alpaca.markets'\n",
    "\n",
    "# Initialize Alpaca API\n",
    "alpaca = tradeapi.REST(ALPACA_API_KEY, ALPACA_SECRET_KEY, base_url=ALPACA_URL, api_version='v2')\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_historical_stock_data(symbols, start_date, end_date):\n",
    "    # Use the correct TimeFrame object for daily data\n",
    "    timeframe = tradeapi.TimeFrame.Day\n",
    "    \n",
    "    all_data = []\n",
    "    \n",
    "    for symbol in symbols:\n",
    "        bars = alpaca.get_bars(\n",
    "            symbol,\n",
    "            timeframe=timeframe,\n",
    "            start=start_date.strftime('%Y-%m-%dT%H:%M:%SZ'),\n",
    "            end=end_date.strftime('%Y-%m-%dT%H:%M:%SZ'),\n",
    "            adjustment='raw',\n",
    "            feed='iex'\n",
    "        )\n",
    "        \n",
    "        data = []\n",
    "        for bar in bars:\n",
    "            data.append({\n",
    "                'symbol': symbol,  # Add the symbol to the data\n",
    "                'time': bar.t,\n",
    "                'open': bar.o,\n",
    "                'high': bar.h,\n",
    "                'low': bar.l,\n",
    "                'close': bar.c,\n",
    "                'volume': bar.v\n",
    "            })\n",
    "        \n",
    "        all_data.extend(data)\n",
    "    \n",
    "    return pd.DataFrame(all_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_50_sp500_stocks = [\n",
    "    'AAPL',  # Apple Inc.\n",
    "    'MSFT',  # Microsoft Corporation\n",
    "    'AMZN',  # Amazon.com Inc.\n",
    "    'NVDA',  # NVIDIA Corporation\n",
    "    'GOOGL', # Alphabet Inc. (Class A)\n",
    "    'GOOG',  # Alphabet Inc. (Class C)\n",
    "    'TSLA',  # Tesla Inc.\n",
    "    'META',  # Meta Platforms Inc.\n",
    "    'BRK.B', # Berkshire Hathaway Inc. (Class B)\n",
    "    'UNH',   # UnitedHealth Group Incorporated\n",
    "    'JNJ',   # Johnson & Johnson\n",
    "    'XOM',   # Exxon Mobil Corporation\n",
    "    'V',     # Visa Inc.\n",
    "    'PG',    # Procter & Gamble Co.\n",
    "    'JPM',   # JPMorgan Chase & Co.\n",
    "    'LLY',   # Eli Lilly and Company\n",
    "    'MA',    # Mastercard Incorporated\n",
    "    'HD',    # The Home Depot Inc.\n",
    "    'CVX',   # Chevron Corporation\n",
    "    'MRK',   # Merck & Co. Inc.\n",
    "    'PEP',   # PepsiCo Inc.\n",
    "    'ABBV',  # AbbVie Inc.\n",
    "    'KO',    # The Coca-Cola Company\n",
    "    'PFE',   # Pfizer Inc.\n",
    "    'AVGO',  # Broadcom Inc.\n",
    "    'COST',  # Costco Wholesale Corporation\n",
    "    'MCD',   # McDonald's Corporation\n",
    "    'TMO',   # Thermo Fisher Scientific Inc.\n",
    "    'WMT',   # Walmart Inc.\n",
    "    'DHR',   # Danaher Corporation\n",
    "    'NKE',   # NIKE Inc.\n",
    "    'DIS',   # The Walt Disney Company\n",
    "    'ADBE',  # Adobe Inc.\n",
    "    'NFLX',  # Netflix Inc.\n",
    "    'VZ',    # Verizon Communications Inc.\n",
    "    'CSCO',  # Cisco Systems Inc.\n",
    "    'ABT',   # Abbott Laboratories\n",
    "    'ACN',   # Accenture plc\n",
    "    'NEE',   # NextEra Energy Inc.\n",
    "    'LIN',   # Linde plc\n",
    "    'TXN',   # Texas Instruments Incorporated\n",
    "    'MDT',   # Medtronic plc\n",
    "    'PM',    # Philip Morris International Inc.\n",
    "    'WFC',   # Wells Fargo & Company\n",
    "    'HON',   # Honeywell International Inc.\n",
    "    'QCOM',  # QUALCOMM Incorporated\n",
    "    'BMY',   # Bristol-Myers Squibb Company\n",
    "    'LOW',   # Lowe's Companies Inc.\n",
    "    'UNP',   # Union Pacific Corporation\n",
    "    'RTX'    # Raytheon Technologies Corporation\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     symbol                      time     open     high      low    close  \\\n",
      "0      AAPL 2024-07-22 00:00:00-04:00  227.335  227.770  223.180  224.160   \n",
      "1      AAPL 2024-07-23 00:00:00-04:00  224.365  226.925  222.680  224.920   \n",
      "2      AAPL 2024-07-24 00:00:00-04:00  224.115  224.765  217.165  218.585   \n",
      "3      AAPL 2024-07-25 00:00:00-04:00  218.880  220.810  214.640  217.420   \n",
      "4      AAPL 2024-07-26 00:00:00-04:00  218.940  219.480  216.040  218.030   \n",
      "...     ...                       ...      ...      ...      ...      ...   \n",
      "1045    RTX 2024-08-13 00:00:00-04:00  116.890  117.165  116.070  116.830   \n",
      "1046    RTX 2024-08-14 00:00:00-04:00  116.760  117.800  116.695  117.640   \n",
      "1047    RTX 2024-08-15 00:00:00-04:00  118.430  118.775  117.535  118.360   \n",
      "1048    RTX 2024-08-16 00:00:00-04:00  117.930  118.410  117.575  117.960   \n",
      "1049    RTX 2024-08-19 00:00:00-04:00  117.975  118.520  117.975  118.350   \n",
      "\n",
      "       volume  \n",
      "0      472525  \n",
      "1      465219  \n",
      "2     1005989  \n",
      "3      642703  \n",
      "4      661067  \n",
      "...       ...  \n",
      "1045   139769  \n",
      "1046   192833  \n",
      "1047   140631  \n",
      "1048   348299  \n",
      "1049    66667  \n",
      "\n",
      "[1050 rows x 7 columns]\n"
     ]
    }
   ],
   "source": [
    "# Retrieve historical stock data for the past year\n",
    "end_date = datetime.utcnow()\n",
    "start_date = end_date - timedelta(days=30)\n",
    "historical_data = get_historical_stock_data(top_50_sp500_stocks, start_date, end_date)\n",
    "\n",
    "print(historical_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Use Alpaca API to return News Articles\n",
    "\n",
    "The get_news function returns articles for the specified period. The function takes in a stock symbol, the max return results, and number of days. The default number of days is 1, and default max results is 200."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from datetime import datetime, timedelta\n",
    "import time\n",
    "\n",
    "def get_news(symbols, days_prior=1):\n",
    "    today = datetime.utcnow()\n",
    "    yesterday = today - timedelta(days=days_prior)  # Adjusted to retrieve news from the previous day\n",
    "    url = \"https://data.alpaca.markets/v1beta1/news\"\n",
    "    headers = {\n",
    "        \"APCA-API-KEY-ID\": ALPACA_API_KEY,\n",
    "        \"APCA-API-SECRET-KEY\": ALPACA_SECRET_KEY\n",
    "    }\n",
    "    news = []\n",
    "    page_token = None\n",
    "    \n",
    "    while True:\n",
    "        params = {\n",
    "            \"symbols\": \",\".join(symbols),\n",
    "            \"start\": start_date.strftime('%Y-%m-%dT%H:%M:%SZ'),\n",
    "            \"end\": today.strftime('%Y-%m-%dT%H:%M:%SZ'),\n",
    "            \"limit\": 50,  # Maximum allowed by the API\n",
    "            \"page_token\": page_token  # For pagination\n",
    "        }\n",
    "        try:\n",
    "            response = requests.get(url, headers=headers, params=params)\n",
    "            response.raise_for_status()\n",
    "            result = response.json()\n",
    "            \n",
    "            news.extend(result.get('news', []))\n",
    "            \n",
    "            # Get the next page token if available\n",
    "            page_token = result.get('next_page_token')\n",
    "            \n",
    "            if not page_token:  # No more pages to fetch\n",
    "                break\n",
    "            \n",
    "        except requests.exceptions.HTTPError as e:\n",
    "            if response.status_code == 429:\n",
    "                print(\"Rate limit reached. Sleeping for 10 seconds...\")\n",
    "                time.sleep(1)  # Wait for 60 seconds before retrying\n",
    "            else:\n",
    "                print(f\"HTTP error occurred: {e}\")\n",
    "                break\n",
    "        except Exception as e:\n",
    "            print(f\"An error occurred: {e}\")\n",
    "            break\n",
    "        \n",
    "    return news\n",
    "\n",
    "# Example usage\n",
    "\n",
    "# Retrieve news for specific symbols\n",
    "\n",
    "news = get_news(top_50_sp500_stocks, days_prior=30)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['2024-08-19' '2024-08-18' '2024-08-17' '2024-08-16' '2024-08-05'\n",
      " '2024-08-15' '2024-08-12' '2024-08-14' '2024-08-09' '2024-08-13'\n",
      " '2024-08-03' '2024-08-11' '2024-08-10' '2024-07-22' '2024-08-08'\n",
      " '2024-08-07' '2024-08-06' '2024-08-02' '2024-08-04' '2024-08-01'\n",
      " '2024-07-31' '2024-07-30' '2024-06-18' '2024-07-29' '2023-12-01'\n",
      " '2024-07-28' '2024-07-27' '2024-04-29' '2024-07-26' '2024-07-24'\n",
      " '2024-07-25' '2024-07-23' '2024-07-21']\n"
     ]
    }
   ],
   "source": [
    "news_df = pd.DataFrame(news)\n",
    "\n",
    "# list all unique dates (not times) in news_df\n",
    "\n",
    "unique_dates = news_df['created_at'].apply(lambda x: x.split('T')[0]).unique()\n",
    "\n",
    "print(unique_dates)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.11/site-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from transformers import pipeline, BertTokenizer, BertForSequenceClassification\n",
    "import pandas as pd\n",
    "\n",
    "# Load the model and tokenizer\n",
    "model_name = \"yiyanghkust/finbert-tone\"  # Example of a financial sentiment model\n",
    "tokenizer = BertTokenizer.from_pretrained(model_name)\n",
    "model = BertForSequenceClassification.from_pretrained(model_name)\n",
    "nlp = pipeline(\"sentiment-analysis\", model=model, tokenizer=tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to split text into 512-token chunks based on tokenization\n",
    "def split_into_chunks(text, max_length=500):\n",
    "    tokens = tokenizer(text, return_tensors=\"pt\", truncation=False)['input_ids'][0]\n",
    "    # Ensure each chunk is no more than 512 tokens\n",
    "    chunks = []\n",
    "    for i in range(0, len(tokens), max_length):\n",
    "        chunk = tokens[i:i + max_length]\n",
    "        # Make sure the chunk is exactly 512 tokens or less\n",
    "        if len(chunk) > max_length:\n",
    "            chunk = chunk[:max_length]\n",
    "        chunks.append(chunk)\n",
    "    return chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to analyze sentiment for long texts\n",
    "def analyze_sentiment(text):\n",
    "    chunks = split_into_chunks(text)\n",
    "    sentiments = []\n",
    "    for chunk in chunks:\n",
    "        # Convert tokens back to text before sentiment analysis\n",
    "        chunk_text = tokenizer.decode(chunk, skip_special_tokens=True)\n",
    "        sentiments.append(nlp(chunk_text)[0])\n",
    "    \n",
    "    # Aggregate sentiment scores (e.g., by averaging)\n",
    "    avg_sentiment_score = sum(s['score'] for s in sentiments) / len(sentiments)\n",
    "    # Determine overall sentiment by majority vote or averaging\n",
    "    positive_scores = sum(s['score'] for s in sentiments if s['label'] == 'positive')\n",
    "    negative_scores = sum(s['score'] for s in sentiments if s['label'] == 'negative')\n",
    "    sentiment_label = 'positive' if positive_scores >= negative_scores else 'negative'\n",
    "    \n",
    "    return sentiment_label, avg_sentiment_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to calculate the overall sentiment score\n",
    "def calculate_overall_sentiment(row):\n",
    "    content_label, content_score = analyze_sentiment(row['content'])\n",
    "    headline_label, headline_score = analyze_sentiment(row['headline'])\n",
    "    \n",
    "    # Average the sentiment scores of content and headline\n",
    "    overall_score = (content_score + headline_score) / 2\n",
    "    overall_label = 'positive' if (content_score + headline_score) >= 1 else 'negative'\n",
    "    \n",
    "    return overall_label, overall_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply the overall sentiment analysis function to your DataFrame\n",
    "news_df['sentiment'], news_df['sentiment_score'] = zip(*news_df['headline'].apply(analyze_sentiment))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          date  average_sentiment_score\n",
      "0   2023-12-01                 0.999948\n",
      "1   2024-04-29                 0.961141\n",
      "2   2024-06-18                 0.510231\n",
      "3   2024-07-21                 0.962439\n",
      "4   2024-07-22                 0.969042\n",
      "5   2024-07-23                 0.960296\n",
      "6   2024-07-24                 0.952226\n",
      "7   2024-07-25                 0.961484\n",
      "8   2024-07-26                 0.963447\n",
      "9   2024-07-27                 0.837638\n",
      "10  2024-07-28                 0.999872\n",
      "11  2024-07-29                 0.949442\n",
      "12  2024-07-30                 0.963917\n",
      "13  2024-07-31                 0.954561\n",
      "14  2024-08-01                 0.956118\n",
      "15  2024-08-02                 0.954622\n",
      "16  2024-08-03                 0.952031\n",
      "17  2024-08-04                 0.909672\n",
      "18  2024-08-05                 0.955715\n",
      "19  2024-08-06                 0.967089\n",
      "20  2024-08-07                 0.978305\n",
      "21  2024-08-08                 0.939025\n",
      "22  2024-08-09                 0.978020\n",
      "23  2024-08-10                 0.916422\n",
      "24  2024-08-11                 0.971428\n",
      "25  2024-08-12                 0.960118\n",
      "26  2024-08-13                 0.952734\n",
      "27  2024-08-14                 0.967978\n",
      "28  2024-08-15                 0.963038\n",
      "29  2024-08-16                 0.972857\n",
      "30  2024-08-17                 0.942961\n",
      "31  2024-08-18                 0.999287\n",
      "32  2024-08-19                 0.963721\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Assume your DataFrame is named `news_df`\n",
    "\n",
    "# Step 1: Convert 'created_at' column to datetime format\n",
    "news_df['created_at'] = pd.to_datetime(news_df['created_at'])\n",
    "\n",
    "# Step 2: Extract the date (without the time) from the 'created_at' column\n",
    "news_df['date'] = news_df['created_at'].dt.date\n",
    "\n",
    "# Step 3: Group by the extracted date and calculate the average sentiment score\n",
    "daily_sentiment = news_df.groupby('date')['sentiment_score'].mean().reset_index()\n",
    "\n",
    "# Step 4: Rename the columns for clarity\n",
    "daily_sentiment.columns = ['date', 'average_sentiment_score']\n",
    "\n",
    "# Display the result\n",
    "print(daily_sentiment)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Assuming `historical_data` is your DataFrame containing historical stock data\n",
    "# Convert the 'time' column to datetime if it's not already\n",
    "historical_data['time'] = pd.to_datetime(historical_data['time'])\n",
    "\n",
    "# Extract the date part from the 'time' column\n",
    "historical_data['date'] = historical_data['time'].dt.date\n",
    "\n",
    "# Calculate the daily percentage change in closing price\n",
    "historical_data['price_change_pct'] = historical_data['close'].pct_change() * 100\n",
    "\n",
    "# Remove the first row since it will have NaN for the percentage change\n",
    "historical_data = historical_data.dropna(subset=['price_change_pct'])\n",
    "\n",
    "# Select only relevant columns\n",
    "historical_data = historical_data[['date', 'price_change_pct']]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>price_change_pct</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2023-08-22</td>\n",
       "      <td>0.158415</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2023-08-23</td>\n",
       "      <td>1.403318</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2023-08-24</td>\n",
       "      <td>-2.120957</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2023-08-25</td>\n",
       "      <td>0.881140</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2023-08-28</td>\n",
       "      <td>0.312829</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>246</th>\n",
       "      <td>2024-08-13</td>\n",
       "      <td>1.678339</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>247</th>\n",
       "      <td>2024-08-14</td>\n",
       "      <td>0.694814</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>248</th>\n",
       "      <td>2024-08-15</td>\n",
       "      <td>1.011628</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>249</th>\n",
       "      <td>2024-08-16</td>\n",
       "      <td>-0.563119</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>250</th>\n",
       "      <td>2024-08-19</td>\n",
       "      <td>0.704898</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>250 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           date  price_change_pct\n",
       "1    2023-08-22          0.158415\n",
       "2    2023-08-23          1.403318\n",
       "3    2023-08-24         -2.120957\n",
       "4    2023-08-25          0.881140\n",
       "5    2023-08-28          0.312829\n",
       "..          ...               ...\n",
       "246  2024-08-13          1.678339\n",
       "247  2024-08-14          0.694814\n",
       "248  2024-08-15          1.011628\n",
       "249  2024-08-16         -0.563119\n",
       "250  2024-08-19          0.704898\n",
       "\n",
       "[250 rows x 2 columns]"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "historical_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          date  average_sentiment_score  price_change_pct\n",
      "0   2024-07-30                 0.969766         -0.944435\n",
      "1   2024-07-31                 0.995069         -1.102489\n",
      "2   2024-08-01                 0.891831         -0.236831\n",
      "3   2024-08-02                 0.991313         -2.040621\n",
      "4   2024-08-05                 0.938245         -3.214041\n",
      "5   2024-08-06                 0.943883          1.019247\n",
      "6   2024-08-07                 0.985208         -0.207801\n",
      "7   2024-08-08                 0.935992          1.111418\n",
      "8   2024-08-09                 0.974452          0.741899\n",
      "9   2024-08-12                 0.949040          0.231521\n",
      "10  2024-08-13                 0.985811          1.678339\n",
      "11  2024-08-14                 0.974394          0.694814\n",
      "12  2024-08-15                 0.974634          1.011628\n",
      "13  2024-08-16                 0.961011         -0.563119\n",
      "14  2024-08-19                 0.976414          0.704898\n"
     ]
    }
   ],
   "source": [
    "# Assuming `daily_sentiment` is your DataFrame containing average sentiment scores by date\n",
    "\n",
    "# Merge the sentiment data with the stock price data on the 'date' column\n",
    "merged_df = pd.merge(daily_sentiment, historical_data, on='date', how='inner')\n",
    "\n",
    "# Display the merged DataFrame\n",
    "print(merged_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          date  average_sentiment_score  price_change_pct  \\\n",
      "0   2024-07-30                 0.904350         -0.944435   \n",
      "1   2024-07-31                 0.925414         -1.102489   \n",
      "2   2024-08-01                 0.962532         -0.236831   \n",
      "3   2024-08-02                 0.868525         -2.040621   \n",
      "4   2024-08-05                 0.981000         -3.214041   \n",
      "5   2024-08-06                 0.941374          1.019247   \n",
      "6   2024-08-07                 0.965586         -0.207801   \n",
      "7   2024-08-08                 0.928285          1.111418   \n",
      "8   2024-08-09                 0.933163          0.741899   \n",
      "9   2024-08-12                 0.897671          0.231521   \n",
      "10  2024-08-13                 0.938136          1.678339   \n",
      "11  2024-08-14                 0.940602          0.694814   \n",
      "12  2024-08-15                 0.919611          1.011628   \n",
      "13  2024-08-16                 0.947846         -0.563119   \n",
      "14  2024-08-19                 0.997491          0.704898   \n",
      "\n",
      "    normalized_sentiment  normalized_price_change  \n",
      "0               0.277789                 0.463906  \n",
      "1               0.441118                 0.431600  \n",
      "2               0.728928                 0.608540  \n",
      "3               0.000000                 0.239847  \n",
      "4               0.872126                 0.000000  \n",
      "5               0.564866                 0.865282  \n",
      "6               0.752606                 0.614474  \n",
      "7               0.463375                 0.884122  \n",
      "8               0.501198                 0.808592  \n",
      "9               0.225999                 0.704271  \n",
      "10              0.539766                 1.000000  \n",
      "11              0.558880                 0.798968  \n",
      "12              0.396119                 0.863725  \n",
      "13              0.615055                 0.541847  \n",
      "14              1.000000                 0.801029  \n"
     ]
    }
   ],
   "source": [
    "# normalize the average sentiment score\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "# Normalize the 'average_sentiment_score' and 'price_change_pct' columns\n",
    "\n",
    "scaler = MinMaxScaler()\n",
    "merged_df[['normalized_sentiment', 'normalized_price_change']] = scaler.fit_transform(merged_df[['average_sentiment_score', 'price_change_pct']])\n",
    "print(merged_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Correlation between sentiment score and stock price change: 0.03302646570894096\n"
     ]
    }
   ],
   "source": [
    "# Calculate the correlation between sentiment score and stock price change\n",
    "correlation = merged_df['average_sentiment_score'].corr(merged_df['price_change_pct'])\n",
    "\n",
    "print(f'Correlation between sentiment score and stock price change: {correlation}')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
